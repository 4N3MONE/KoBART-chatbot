{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoBART-chitchat.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy6rzE3uZfJQ",
        "outputId": "6f183a40-3bb9-45cc-f989-7973461ebf48"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Dec  8 13:20:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsXJJajPeJ7M",
        "outputId": "c9a3108a-9c9f-40b0-b6f9-6ecb952c22f1"
      },
      "source": [
        "# 현재 CUDA Version에 맞는 Pytorch 설치\n",
        "!pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html pytorch_lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.0+cu101 in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision==0.8.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: torchaudio===0.7.0 in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cu101) (0.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.1+cu101) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (0.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (5.3.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_lightning) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.17.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwv3kJTedw1E",
        "outputId": "a350dafa-365c-4c0f-aeb0-088b98dfac64"
      },
      "source": [
        "!git clone https://github.com/SKT-AI/KoBART.git\n",
        "!pip install -r KoBART/requirements.txt\n",
        "!pip install KoBART/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'KoBART' already exists and is not an empty directory.\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from -r KoBART/requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: transformers==4.0.0 in /usr/local/lib/python3.6/dist-packages (from -r KoBART/requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->-r KoBART/requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->-r KoBART/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->-r KoBART/requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->-r KoBART/requirements.txt (line 1)) (0.18.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0->-r KoBART/requirements.txt (line 2)) (7.1.2)\n",
            "Processing ./KoBART\n",
            "Building wheels for collected packages: kobart\n",
            "  Building wheel for kobart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobart: filename=kobart-0.1.2-cp36-none-any.whl size=8162 sha256=e24b17dc68319347efd222503c9d6af4ed8b04394ad5217d4f7458818cfb9277\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bld7bs2_/wheels/a1/6b/7a/b87ff58042fc4d2ba6420a0edb72d7d04ff247e225eea88dc5\n",
            "Successfully built kobart\n",
            "Installing collected packages: kobart\n",
            "  Found existing installation: kobart 0.1.2\n",
            "    Uninstalling kobart-0.1.2:\n",
            "      Successfully uninstalled kobart-0.1.2\n",
            "Successfully installed kobart-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG68aqVzgsjR",
        "outputId": "a736788f-efcb-465d-9d75-7a3dda2c5398"
      },
      "source": [
        "!git clone --recurse-submodules https://github.com/haven-jeon/KoBART-chatbot.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'KoBART-chatbot'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 15 (delta 2), reused 12 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), done.\n",
            "Submodule 'Chatbot_data' (https://github.com/haven-jeon/Chatbot_data.git) registered for path 'Chatbot_data'\n",
            "Cloning into '/content/KoBART-chatbot/Chatbot_data'...\n",
            "remote: Enumerating objects: 4, done.        \n",
            "remote: Counting objects: 100% (4/4), done.        \n",
            "remote: Compressing objects: 100% (4/4), done.        \n",
            "remote: Total 24 (delta 0), reused 3 (delta 0), pack-reused 20        \n",
            "Submodule path 'Chatbot_data': checked out '05e9a64f49a1d0f040ffc63d74b132e8b1795a23'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqJMwfSgvMn",
        "outputId": "8fff1336-e296-4efc-d5a4-277366eee373"
      },
      "source": [
        "%cd KoBART-chatbot"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/KoBART-chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "iNBhBrMzg_r7",
        "outputId": "2d4a5041-b527-4634-f2c7-73ad23a0402a"
      },
      "source": [
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "get_kobart_tokenizer(\".\")\n",
        "get_pytorch_kobart_model(cachedir=\".\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./kobart_emji_from_pretrained'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBsNZ6IAg3hI",
        "outputId": "5f618963-7c94-4dbe-f681-197ce1c9a750"
      },
      "source": [
        "!python kobart_chit_chat.py  --gradient_clip_val 1.0 --max_epochs 3 --default_root_dir logs --model_path kobart_emji_from_pretrained  --tokenizer_path emji_tokenizer --chat --gpus 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-08 13:24:13.201341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "INFO:root:Namespace(accelerator=None, accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=True, batch_size=14, benchmark=False, chat=True, check_val_every_n_epoch=1, checkpoint_callback=True, checkpoint_path=None, default_root_dir='logs', deterministic=False, distributed_backend=None, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=1, gradient_clip_val=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=5e-05, max_epochs=3, max_seq_len=36, max_steps=None, min_epochs=1, min_steps=None, model_path='kobart_emji_from_pretrained', num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=5, overfit_batches=0.0, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, subtask='NSMC', sync_batchnorm=False, terminate_on_nan=False, test_file='Chatbot_data/test.csv', tokenizer_path='emji_tokenizer', tpu_cores=<function _gpus_arg_default at 0x7f6f748d2c80>, track_grad_norm=-1, train_file='Chatbot_data/train.csv', truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "INFO:lightning:GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning:TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:root:number of workers 1, data length 10640\n",
            "INFO:root:num_train_steps : 2280\n",
            "INFO:root:num_warmup_steps : 228\n",
            "\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 123 M \n",
            "INFO:lightning:\n",
            "  | Name  | Type                         | Params\n",
            "-------------------------------------------------------\n",
            "0 | model | BartForConditionalGeneration | 123 M \n",
            "Epoch 0:  90% 333/370 [01:44<00:11,  3.20it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  91% 335/370 [01:44<00:10,  3.21it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Epoch 0:  91% 337/370 [01:44<00:10,  3.22it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  11% 4/37 [00:00<00:07,  4.64it/s]\u001b[A\n",
            "Epoch 0:  92% 339/370 [01:44<00:09,  3.24it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  16% 6/37 [00:00<00:04,  6.37it/s]\u001b[A\n",
            "Epoch 0:  92% 341/370 [01:44<00:08,  3.25it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Epoch 0:  93% 343/370 [01:45<00:08,  3.26it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  27% 10/37 [00:01<00:03,  8.03it/s]\u001b[A\n",
            "Epoch 0:  93% 345/370 [01:45<00:07,  3.28it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Epoch 0:  94% 347/370 [01:45<00:06,  3.29it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Epoch 0:  94% 349/370 [01:45<00:06,  3.30it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Epoch 0:  95% 351/370 [01:45<00:05,  3.31it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  49% 18/37 [00:02<00:01,  9.65it/s]\u001b[A\n",
            "Epoch 0:  95% 353/370 [01:46<00:05,  3.33it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  54% 20/37 [00:02<00:01,  9.71it/s]\u001b[A\n",
            "Epoch 0:  96% 355/370 [01:46<00:04,  3.34it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  59% 22/37 [00:02<00:01,  9.79it/s]\u001b[A\n",
            "Epoch 0:  96% 357/370 [01:46<00:03,  3.35it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  65% 24/37 [00:02<00:01,  9.86it/s]\u001b[A\n",
            "Epoch 0:  97% 359/370 [01:46<00:03,  3.36it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  70% 26/37 [00:02<00:01,  9.87it/s]\u001b[A\n",
            "Epoch 0:  98% 361/370 [01:46<00:02,  3.38it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  76% 28/37 [00:03<00:00,  9.89it/s]\u001b[A\n",
            "Epoch 0:  98% 363/370 [01:47<00:02,  3.39it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  81% 30/37 [00:03<00:00,  9.88it/s]\u001b[A\n",
            "Epoch 0:  99% 365/370 [01:47<00:01,  3.40it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  86% 32/37 [00:03<00:00,  9.87it/s]\u001b[A\n",
            "Epoch 0:  99% 367/370 [01:47<00:00,  3.41it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  92% 34/37 [00:03<00:00,  9.80it/s]\u001b[A\n",
            "Epoch 0: 100% 369/370 [01:47<00:00,  3.42it/s, loss=3.086, v_num=0, train_loss=2.83]\n",
            "Validating:  97% 36/37 [00:03<00:00,  9.80it/s]\u001b[AEpoch 0: val_loss reached 3.03729 (best 3.03729), saving model to /content/KoBART-chatbot/logs/kobart_chitchat-model_chp/epoch=00-val_loss=3.037.ckpt as top 1\n",
            "INFO:lightning:Epoch 0: val_loss reached 3.03729 (best 3.03729), saving model to /content/KoBART-chatbot/logs/kobart_chitchat-model_chp/epoch=00-val_loss=3.037.ckpt as top 1\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "tcmalloc: large alloc 1123573760 bytes == 0x1330f6000 @  0x7f6fdc299615 0x591e47 0x4cc179 0x4cc2db 0x566f45 0x59fd0e 0x7f6fc8cb1924 0x7f6fc8cb39d4 0x7f6fc8c83370 0x7f6fb95ce435 0x7f6fb95ca99a 0x7f6fb95cf5d9 0x7f6fc8c911ab 0x7f6fc890fc1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd\n",
            "tcmalloc: large alloc 1404469248 bytes == 0x7f6d54498000 @  0x7f6fdc299615 0x591e47 0x4cc179 0x4cc2db 0x566f45 0x59fd0e 0x7f6fc8cb1924 0x7f6fc8cb39d4 0x7f6fc8c83370 0x7f6fb95ce435 0x7f6fb95ca99a 0x7f6fb95cf5d9 0x7f6fc8c911ab 0x7f6fc890fc1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd\n",
            "tcmalloc: large alloc 1755586560 bytes == 0x10878a000 @  0x7f6fdc299615 0x591e47 0x4cc179 0x4cc2db 0x566f45 0x59fd0e 0x7f6fc8cb1924 0x7f6fc8cb39d4 0x7f6fc8c83370 0x7f6fb95ce435 0x7f6fb95ca99a 0x7f6fb95cf5d9 0x7f6fc8c911ab 0x7f6fc890fc1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd\n",
            "Epoch 0: 100% 370/370 [02:00<00:00,  3.07it/s, loss=3.086, v_num=0, train_loss=2.83]tcmalloc: large alloc 1755586560 bytes == 0x10878a000 @  0x7f6fdc299615 0x591e47 0x4cc179 0x4cc2db 0x566f45 0x59fd0e 0x7f6fc8cb1924 0x7f6fc8cb39d4 0x7f6fc8c83370 0x7f6fb95ce435 0x7f6fb95ca99a 0x7f6fb95cf5d9 0x7f6fc8c911ab 0x7f6fc890fc1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd\n",
            "Epoch 0: 100% 370/370 [02:37<00:00,  2.36it/s, loss=3.086, v_num=0, train_loss=2.83, val_loss=3.04]\n",
            "Epoch 1:  90% 333/370 [01:49<00:12,  3.04it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  91% 335/370 [01:50<00:11,  3.05it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Epoch 1:  91% 337/370 [01:50<00:10,  3.06it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  11% 4/37 [00:00<00:07,  4.37it/s]\u001b[A\n",
            "Epoch 1:  92% 339/370 [01:50<00:10,  3.07it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  16% 6/37 [00:00<00:05,  6.10it/s]\u001b[A\n",
            "Epoch 1:  92% 341/370 [01:50<00:09,  3.08it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  22% 8/37 [00:01<00:03,  7.57it/s]\u001b[A\n",
            "Epoch 1:  93% 343/370 [01:50<00:08,  3.09it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  27% 10/37 [00:01<00:03,  8.20it/s]\u001b[A\n",
            "Epoch 1:  93% 345/370 [01:51<00:08,  3.11it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  32% 12/37 [00:01<00:02,  8.98it/s]\u001b[A\n",
            "Epoch 1:  94% 347/370 [01:51<00:07,  3.12it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  38% 14/37 [00:01<00:02,  9.41it/s]\u001b[A\n",
            "Epoch 1:  94% 349/370 [01:51<00:06,  3.13it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Epoch 1:  95% 351/370 [01:51<00:06,  3.14it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  49% 18/37 [00:02<00:01,  9.69it/s]\u001b[A\n",
            "Epoch 1:  95% 353/370 [01:51<00:05,  3.16it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  54% 20/37 [00:02<00:01,  9.38it/s]\u001b[A\n",
            "Epoch 1:  96% 355/370 [01:52<00:04,  3.17it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Epoch 1:  96% 357/370 [01:52<00:04,  3.18it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  65% 24/37 [00:02<00:01,  9.68it/s]\u001b[A\n",
            "Epoch 1:  97% 359/370 [01:52<00:03,  3.19it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  70% 26/37 [00:02<00:01,  9.76it/s]\u001b[A\n",
            "Epoch 1:  98% 361/370 [01:52<00:02,  3.20it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  76% 28/37 [00:03<00:00,  9.72it/s]\u001b[A\n",
            "Epoch 1:  98% 363/370 [01:52<00:02,  3.22it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  81% 30/37 [00:03<00:00,  9.53it/s]\u001b[A\n",
            "Epoch 1:  99% 365/370 [01:53<00:01,  3.23it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  86% 32/37 [00:03<00:00,  9.64it/s]\u001b[A\n",
            "Epoch 1:  99% 367/370 [01:53<00:00,  3.24it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  92% 34/37 [00:03<00:00,  9.75it/s]\u001b[A\n",
            "Epoch 1: 100% 369/370 [01:53<00:00,  3.25it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=3.04]\n",
            "Validating:  97% 36/37 [00:03<00:00,  9.77it/s]\u001b[A\n",
            "Validating: 100% 37/37 [00:04<00:00,  9.75it/s]\u001b[AEpoch 1: val_loss reached 2.64058 (best 2.64058), saving model to /content/KoBART-chatbot/logs/kobart_chitchat-model_chp/epoch=01-val_loss=2.641.ckpt as top 2\n",
            "INFO:lightning:Epoch 1: val_loss reached 2.64058 (best 2.64058), saving model to /content/KoBART-chatbot/logs/kobart_chitchat-model_chp/epoch=01-val_loss=2.641.ckpt as top 2\n",
            "tcmalloc: large alloc 1755586560 bytes == 0x10878a000 @  0x7f6fdc299615 0x591e47 0x4cc179 0x4cc2db 0x566f45 0x59fd0e 0x7f6fc8cb1924 0x7f6fc8cb39d4 0x7f6fc8c83370 0x7f6fb95ce435 0x7f6fb95ca99a 0x7f6fb95cf5d9 0x7f6fc8c911ab 0x7f6fc890fc1a 0x566bbc 0x50a433 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd\n",
            "Epoch 1: 100% 370/370 [02:41<00:00,  2.29it/s, loss=2.271, v_num=0, train_loss=2.44, val_loss=2.64]\n",
            "Epoch 2:  90% 333/370 [01:55<00:12,  2.89it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  91% 335/370 [01:55<00:12,  2.90it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Epoch 2:  91% 337/370 [01:55<00:11,  2.91it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  11% 4/37 [00:00<00:08,  3.99it/s]\u001b[A\n",
            "Epoch 2:  92% 339/370 [01:55<00:10,  2.92it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  16% 6/37 [00:00<00:05,  5.73it/s]\u001b[A\n",
            "Epoch 2:  92% 341/370 [01:56<00:09,  2.94it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  22% 8/37 [00:01<00:03,  7.27it/s]\u001b[A\n",
            "Epoch 2:  93% 343/370 [01:56<00:09,  2.95it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Epoch 2:  93% 345/370 [01:56<00:08,  2.96it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  32% 12/37 [00:01<00:02,  8.44it/s]\u001b[A\n",
            "Epoch 2:  94% 347/370 [01:56<00:07,  2.97it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Epoch 2:  94% 349/370 [01:56<00:07,  2.98it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Epoch 2:  95% 351/370 [01:57<00:06,  3.00it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  49% 18/37 [00:02<00:01,  9.52it/s]\u001b[A\n",
            "Epoch 2:  95% 353/370 [01:57<00:05,  3.01it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  54% 20/37 [00:02<00:01,  9.40it/s]\u001b[A\n",
            "Epoch 2:  96% 355/370 [01:57<00:04,  3.02it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  59% 22/37 [00:02<00:01,  9.48it/s]\u001b[A\n",
            "Epoch 2:  96% 357/370 [01:57<00:04,  3.03it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  65% 24/37 [00:02<00:01,  9.69it/s]\u001b[A\n",
            "Epoch 2:  97% 359/370 [01:58<00:03,  3.04it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  70% 26/37 [00:02<00:01,  9.78it/s]\u001b[A\n",
            "Epoch 2:  98% 361/370 [01:58<00:02,  3.05it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  76% 28/37 [00:03<00:00,  9.77it/s]\u001b[A\n",
            "Epoch 2:  98% 363/370 [01:58<00:02,  3.07it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  81% 30/37 [00:03<00:00,  9.67it/s]\u001b[A\n",
            "Epoch 2:  99% 365/370 [01:58<00:01,  3.08it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  86% 32/37 [00:03<00:00,  9.54it/s]\u001b[A\n",
            "Epoch 2:  99% 367/370 [01:58<00:00,  3.09it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  92% 34/37 [00:03<00:00,  9.69it/s]\u001b[A\n",
            "Epoch 2: 100% 369/370 [01:59<00:00,  3.10it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.64]\n",
            "Validating:  97% 36/37 [00:03<00:00,  9.78it/s]\u001b[A\n",
            "Validating: 100% 37/37 [00:04<00:00,  9.80it/s]\u001b[AEpoch 2: val_loss reached 2.55997 (best 2.55997), saving model to /content/KoBART-chatbot/logs/kobart_chitchat-model_chp/epoch=02-val_loss=2.560.ckpt as top 3\n",
            "INFO:lightning:Epoch 2: val_loss reached 2.55997 (best 2.55997), saving model to /content/KoBART-chatbot/logs/kobart_chitchat-model_chp/epoch=02-val_loss=2.560.ckpt as top 3\n",
            "Epoch 2: 100% 370/370 [02:48<00:00,  2.20it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.56]\n",
            "                                               \u001b[ASaving latest checkpoint...\n",
            "INFO:lightning:Saving latest checkpoint...\n",
            "Epoch 2: 100% 370/370 [02:48<00:00,  2.20it/s, loss=1.491, v_num=0, train_loss=1.53, val_loss=2.56]\n",
            "user > 나 정말 ㅜㅜ.\n",
            "Simsimi >  무슨 일 있었나요.\n",
            "user > 어버이날엔 뭘 하죠?\n",
            "Simsimi >  기념일 챙겨드세요.\n",
            "user > 큰돈을 만드는 방법은?\n",
            "Simsimi >  돈을 만들어해서 주식으로 만들어보세요.\n",
            "user > 집은 너무 비싼거 같아요.\n",
            "Simsimi >  돈을 얼른 모아야할 이유가 생겼네요.\n",
            "user > quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}